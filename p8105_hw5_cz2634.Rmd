---
title: "p8105 HW5"
author: Chenxin Zhang
date: 2020/11/16
output: github_document
---


## Problem 1

```{r setup}
library(tidyverse)
library(rvest)
library(ggplot2)
library(patchwork)
set.seed(1000)
knitr::opts_chunk$set(
  warning = FALSE,
  echo =TRUE,
  message = FALSE,
  fig.height = 8,
  fig.width = 8,
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

Read in the data.

```{r}
#use mutate() to create a new variable
homicide_df = 
  read_csv("./data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL")
```


Let's look at this a bit

```{r}
aggregate_df = 
  homicide_df %>% 
  group_by(city_state) %>% 
  summarize(
    hom_total = n(),
    hom_unsolved = sum(resolved == "unsolved")
  )
```

Can I do a prop test for a single city?

```{r}
# set x and n, the p is null=0.5
#broom::tidy()make the result a table, more clean way
prop.test(
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_unsolved), 
  aggregate_df %>% filter(city_state == "Baltimore_MD") %>% pull(hom_total)) %>% 
  broom::tidy()
```

Try to iterate ........

```{r}
#map2() gives you 2 elements, we get list 
#map broom::tidy across prop_test, we get a tibble for each city
results_df = 
  aggregate_df %>% 
  mutate(
    prop_tests = map2(.x = hom_unsolved, .y = hom_total, ~prop.test(x = .x, n = .y)),
    tidy_tests = map(.x = prop_tests, ~broom::tidy(.x))
  ) %>% 
  select(-prop_tests) %>% 
  unnest(tidy_tests) %>% 
  select(city_state, estimate, conf.low, conf.high)
```



```{r}
results_df %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point() + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


```{r, error = TRUE}
#error = true means that the code will not stop when counter error in this code chunk when knit
city_prop_test = function(df) {
  
  n_unsovled = filter(city_state = df) %>% pull(hom_unsolved)
  n_total = filter(city_state = df) %>% pull(hom_total) 
  
  prop.test(n_unsovled, n_total) 
}

homicide_df = 
  read_csv("data/homicide-data.csv") %>% 
  mutate(
    city_state = str_c(city, state, sep = "_"),
    resolved = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest"        ~ "unsolved",
      disposition == "Closed by arrest"      ~ "solved",
    )
  ) %>% 
  select(city_state, resolved) %>% 
  filter(city_state != "Tulsa_AL") %>% 
  nest(data = resolved)
```

## Problem 2 

**Import several data**
```{r}
#list.files() will list all files in lda_data folder
#use tibble() to create a df contains all file names
#mutate string character in the column 'path'
#map read_csv() across each path 
path_df = 
  tibble(
    path = list.files("./data/lda_data"),
  ) %>% 
  mutate(
    path = str_c("./data/lda_data/", path),
    data = map(.x = path, ~read_csv(.x)))
```

**Tidy data**
```{r}
#tidy data 
#str_replace specific string with nothing, equal to str_remove specific string in column
#separate column to two column by _
#case_when() and recode() to change string name
combined_df = path_df %>% 
  mutate(
    arm = str_replace(path, "./data/lda_data/", ""),
    arm = str_replace(arm, ".csv", "")
) %>% 
  separate(arm, into = c("arm", "subject_ID"), sep = "_") %>% 
  select(arm, subject_ID, data) %>% 
  mutate(
    arm = case_when(
    arm == "con" ~ "control",
    arm == "exp" ~ "experiment")
) %>% 
  unnest(data) %>% 
  pivot_longer(
    week_1:week_8,
    values_to = "data",
    names_to = "week"
) 
```

**Visualization**

```{r}
combined_df %>% 
  unite(arm_id, arm, subject_ID, remove = FALSE) %>%
  ggplot(aes(x = week, y = data)) +
  geom_path(aes(color = arm, group = as.factor(arm_id)),alpha = 0.5) +
  labs(
    x = "Week",
    y = "Observation value",
    title = "The Observations group by subject over 8 weeks"
    )
```
* As shown in the graph, both control group and experiment group has similar observation value at week 1.  As time going on, the observation value of experiment group rise gradually over time, while control group has no  obvious difference from baseline.

## Problem 3

**function with fixed sample size and sigma**
```{r}
sim_mean_ttest = function(samp_size = 30, mu, sigma = 5) {
  
  sim_data = 
    tibble(
      x = rnorm(n = samp_size, mean = mu, sd = sigma)
    )#generate data from a normal distribution
  sim_data %>% 
    summarize(
        t_test = t.test(x, mu = 0, conf.level = 0.95) %>% 
        broom::tidy() %>% 
        select(p.value, estimate)
    ) %>% 
    mutate(p_value = t_test$p.value,
            mu_hat = t_test$estimate) %>% 
    select(mu_hat,p_value)
}
```


**simulate 5000 times by using 'for loop' when mu = 0**
```{r}
output = vector("list", length = 5000)#vector of type list
for (i in 1:5000) {
  
  output[[i]] = sim_mean_ttest(mu = 0)
  
}
bind_rows(output)#not a list but data frame

```

**Repeat the above for μ={0,1,2,3,4,5,6}**

```{r repaet_process, cache = TRUE}
# make a tibble and use mutate to add the result as new column
# maping  mu across return(), get a list column
# .x means that the first argument to map is .x; tidle means put the .x to the function; whatever the first sample size is , it is going to get plugged in over the function
## there are 5000 lists in the first list, so we combine the 5000 list to a tibble
sim_results =
  tibble(
    mu = c(0, 1, 2, 3, 4, 5, 6)
  ) %>% 
  mutate(
    output_lists = map(.x = mu, ~rerun(5000, sim_mean_ttest(mu = .x))),
    results_df = map(output_lists, bind_rows)
  ) %>% 
  select(-output_lists) %>% 
  unnest(results_df)
```

**one plot showing the proportion of times the null was rejected**

```{r}

plot_1 = sim_results %>% 
  filter(p_value < 0.05) %>%
  group_by(mu) %>% 
  summarize(
    rejection = n()
  ) %>% 
  mutate(prop_of_rej = rejection / 5000) %>% 
  ggplot(aes(x = mu, y = prop_of_rej, color = mu)) +
  geom_point() + 
  geom_line() +
  ylim(0,1) +
  geom_text(aes(label = prop_of_rej, hjust = 0, vjust = 0.5)) +
  scale_x_continuous(limits = c(0,6), breaks = seq(0,6,1)) +
  labs(
    title = "Power of the test",
    x = "True mu",
    y = "Power"
  )

plot_1
```

* According to the plot above, as effect size(mu) increase the power of rejecting the null hypothesis (mu=0) also increase, and nearly close to 1 as true mu close to 4.

**One plot showing relationships between the average estimated mu and true value of mu.**

```{r}
plot_2 = 
  sim_results %>% 
  group_by(mu) %>% 
  summarize(ave_est_mu = mean(mu_hat)) %>% 
  ggplot(aes(x = mu, y = ave_est_mu, color = mu)) +
  geom_point() +geom_line() +
  scale_x_continuous(limits = c(0,6), breaks = seq(0,6,1)) +
  scale_y_continuous(limits = c(-1,7), breaks = seq(-1,7,1)) +
  labs(
    title = "The average estimated mu and true value of mu",
    x = "True mu",
    y = "Ave_est_mu"
  )

plot_2
```

**One plot showing the average estimate of mu and true value of mu only in samples for which the null was rejected.**

```{r}
plot_3 =
  sim_results %>% 
  filter(p_value < 0.05) %>% 
  group_by(mu) %>% 
  summarize(
    ave_est_mu = mean(mu_hat)
  ) %>% 
  ggplot(aes(x = mu, y = ave_est_mu, color = mu)) +
  geom_point() + geom_line()+
  scale_x_continuous(limits = c(0,6), breaks = seq(0,6,1)) +
  scale_y_continuous(limits = c(-1,7), breaks = seq(-1,7,1)) +
  labs(
    title = "The average estimated mu and true value of mu when null is rejected",
    x = "True mu",
    y = "Ave_est_mu"
  )

plot_3
```

```{r}
plot_2 / plot_3
```

**Is the sample average of μ^ across tests for which the null is rejected approximately equal to the true value of μ? Why or why not?**

* According to the plot above, for u smaller than 3, the answer is no. The sample average of mu for which the null is rejected is not equal to the true value of mu. 
* For u equal or larger than 3, the answer is yes. we can observe that as mu close to 3 or larger, the average of estimate mu across tests  equal to the true value of μ in the condition that the null is rejected.
* The reason is that the power of the test increase when we increase the effect size(mu) as shown in plot_1.
















